{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.utils.data as tud\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter, defaultdict\n",
    "import operator\n",
    "import os, math\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/crismacg/Desktop/aml/ml_nlp_conflict\n"
     ]
    }
   ],
   "source": [
    "cd 'Desktop/aml/ml_nlp_conflict/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/crismacg/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/acled_all.csv')\n",
    "VOCAB_SIZE = 5000\n",
    "seed = 30255\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(l):\n",
    "    STOP  = ['ourselves', 'hers', 'between', 'yourself', 'but', 'again', 'there', 'about', 'once', 'during', 'out', 'very', 'having', 'with', 'they', 'own', 'an', 'be', 'some', 'for', 'do', 'its', 'yours', 'such', 'into', 'of', 'most', 'itself', 'other', 'off', 'is', 's', 'am', 'or', 'who', 'as', 'from', 'him', 'each', 'the', 'themselves', 'until', 'below', 'are', 'we', 'these', 'your', 'his', 'through', 'don', 'nor', 'me', 'were', 'her', 'more', 'himself', 'this', 'down', 'should', 'our', 'their', 'while', 'above', 'both', 'up', 'to', 'ours', 'had', 'she', 'all', 'no', 'when', 'at', 'any', 'before', 'them', 'same', 'and', 'been', 'have', 'in', 'will', 'on', 'does', 'yourselves', 'then', 'that', 'because', 'what', 'over', 'why', 'so', 'can', 'did', 'not', 'now', 'under', 'he', 'you', 'herself', 'has', 'just', 'where', 'too', 'only', 'myself', 'which', 'those', 'i', 'after', 'few', 'whom', 't', 'being', 'if', 'theirs', 'my', 'against', 'a', 'by', 'doing', 'it', 'how', 'further', 'was', 'here', 'than']\n",
    "    l_clean = []\n",
    "    for i in l:\n",
    "        if i not in STOP:\n",
    "            l_clean.append(i)\n",
    "    return l_clean\n",
    "\n",
    "\n",
    "def word_tokenize(s, clean = False):\n",
    "    if type(s) != str:\n",
    "        return None\n",
    "    split_l = s.lower().replace('.', '').replace(',', '').replace(';', '').replace(':', '').replace('!', '').replace('?', '').split()\n",
    "    if clean:\n",
    "        clean_l = remove_stopwords(split_l)\n",
    "        return clean_l\n",
    "\n",
    "    return split_l\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, data, clean = False):\n",
    "        # Vocabulary is a set that stores every word seen in the\n",
    "        # training data\n",
    "        self.vocab_counts = Counter([word for content in data\n",
    "                              for word in word_tokenize(content, clean) if word]\n",
    "                            ).most_common(VOCAB_SIZE-1)\n",
    "        # word to index mapping\n",
    "        self.word_to_idx = {k[0]: v+1 for v, k in\n",
    "                            enumerate(self.vocab_counts)}\n",
    "        # all the unknown words will be mapped to index 0\n",
    "        self.word_to_idx[\"UNK\"] = 0\n",
    "        self.vocab = set(self.word_to_idx.keys())\n",
    "\n",
    "        self.verb_counts = Counter([token.lemma_ for content in data\n",
    "                              for token in nlp(content) if token.pos_ == \"VERB\"]\n",
    "                            ).most_common(VOCAB_SIZE-1)\n",
    "\n",
    "        self.noun_counts = Counter([chunk.text for content in data\n",
    "                              for chunk in nlp(content).noun_chunks]\n",
    "                            ).most_common(VOCAB_SIZE-1)\n",
    "\n",
    "\n",
    "class TextClassificationDataset(tud.Dataset):\n",
    "    '''\n",
    "    PyTorch provides a common dataset interface.\n",
    "    See https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "    The dataset encodes documents into indices.\n",
    "    With the PyTorch dataloader, you can easily get batched data for\n",
    "    training and evaluation.\n",
    "    '''\n",
    "    def __init__(self, word_to_idx, data):\n",
    "\n",
    "        self.data = data\n",
    "        self.word_to_idx = word_to_idx\n",
    "        self.vocab_size = VOCAB_SIZE\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = np.zeros(self.vocab_size)\n",
    "        item = torch.from_numpy(item)\n",
    "        for word in word_tokenize(self.data[idx]):\n",
    "            item[self.word_to_idx.get(word, 0)] += 1\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******************************************************************************\n",
    "# Get list of verbs for all data\n",
    "# ******************************************************************************\n",
    "data.dropna(subset=['NOTES'], inplace = True)\n",
    "# x_wstopwords = Model(data['NOTES'], False)\n",
    "# verb_count_complete = x_wstopwords.verb_counts\n",
    "\n",
    "# verb_count_complete # This was exported to a csv and then manually classified. Then we imported it back "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******************************************************************************\n",
    "# Subset my data\n",
    "# ******************************************************************************\n",
    "mlist = [26, 27, 36, 37, 56, 57]\n",
    "data_filtered = data.loc[data['INTERACTION'].isin(mlist)]\n",
    "data_filtered.shape\n",
    "\n",
    "final_data = data_filtered.loc[data_filtered['NOTES'].str.len() > 100 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******************************************************************************\n",
    "# Getting the nouns for a subset of type of events in which we know civilians are attacked\n",
    "# ******************************************************************************\n",
    "\n",
    "# data_filt2 = data_filtered[data_filtered['ACTOR2'].str.contains('Civilians') == True]\n",
    "# z_wstopwords = Model(data_filt2['NOTES'], False)\n",
    "#\n",
    "# noun_count_complete = z_wstopwords.noun_counts\n",
    "# noun_count_filtered = noun_count_complete\n",
    "#\n",
    "\n",
    "# ******************************************************************************\n",
    "# Turn into list of verbs\n",
    "# ******************************************************************************\n",
    "\n",
    "# Remove verbs we're not interested in\n",
    "\n",
    "# vbs_complete = [word for word, count in verb_count_complete]\n",
    "# vbs_filtered = [word for word, count in verb_count_filtered]\n",
    "#\n",
    "# noun_filtered = [word for word, count in noun_count_filtered]\n",
    "# print(vbs_complete)\n",
    "# print(vbs_filtered)\n",
    "# print(noun_count_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        kill\n",
       "3      injure\n",
       "4       stage\n",
       "6     protest\n",
       "8      attack\n",
       "9      demand\n",
       "10       hold\n",
       "11      shell\n",
       "12      wound\n",
       "14      shoot\n",
       "15      clash\n",
       "16       lead\n",
       "20       fire\n",
       "22     arrest\n",
       "24        hit\n",
       "Name: clean_list, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ******************************************************************************\n",
    "# Read processed list of verbs\n",
    "# ******************************************************************************\n",
    "vbs = pd.read_csv('data/verbs.csv')\n",
    "vbs.head()\n",
    "\n",
    "vbs['clean_list'] = vbs['List'].str.replace('(', '')\n",
    "vbs['clean_list'] = vbs['clean_list'].str.replace('[', '')\n",
    "vbs['clean_list'] = vbs['clean_list'].str.replace(']', '')\n",
    "vbs['clean_list'] = vbs['clean_list'].str.replace(\"'\", '')\n",
    "vbs['clean_list'] = vbs['clean_list'].str.strip()\n",
    "\n",
    "vbs = vbs[vbs['Filter'] == 1]\n",
    "vbs.shape\n",
    "list_vbs = vbs.clean_list\n",
    "list_vbs[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/crismacg/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/crismacg/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/68\n",
      "1/68\n",
      "2/68\n",
      "3/68\n",
      "4/68\n",
      "5/68\n",
      "6/68\n",
      "7/68\n",
      "8/68\n",
      "9/68\n",
      "10/68\n",
      "11/68\n",
      "12/68\n",
      "13/68\n",
      "14/68\n",
      "15/68\n",
      "16/68\n",
      "17/68\n",
      "18/68\n",
      "19/68\n",
      "20/68\n",
      "21/68\n",
      "22/68\n",
      "23/68\n",
      "24/68\n",
      "25/68\n",
      "26/68\n",
      "27/68\n",
      "28/68\n",
      "29/68\n",
      "30/68\n",
      "31/68\n",
      "32/68\n",
      "33/68\n",
      "34/68\n",
      "35/68\n",
      "36/68\n",
      "37/68\n",
      "38/68\n",
      "39/68\n",
      "40/68\n",
      "41/68\n",
      "42/68\n",
      "43/68\n",
      "44/68\n",
      "45/68\n",
      "46/68\n",
      "47/68\n",
      "48/68\n",
      "49/68\n",
      "50/68\n",
      "51/68\n",
      "52/68\n",
      "53/68\n",
      "54/68\n",
      "55/68\n",
      "56/68\n",
      "57/68\n",
      "58/68\n",
      "59/68\n",
      "60/68\n",
      "61/68\n",
      "62/68\n",
      "63/68\n",
      "64/68\n",
      "65/68\n",
      "66/68\n",
      "67/68\n",
      "end_loop\n",
      "we lose 2445 observations by filtering through our classification of relationship, which is equivalent to 5.99529204060615 %\n"
     ]
    }
   ],
   "source": [
    "# ******************************************************************************\n",
    "# Create automatic labelling.\n",
    "# ******************************************************************************\n",
    "final_data['tagged_rel'] = ''\n",
    "num_v = len(list_vbs)\n",
    "for cnt, vb in enumerate(list_vbs):\n",
    "    final_data['tagged_rel'] = final_data.apply(lambda x: vb if (vb in x['NOTES'] and x['tagged_rel'] == '') else x['tagged_rel'], axis =1)\n",
    "    print(str(cnt) + '/' + str(num_v))\n",
    "print('end_loop')\n",
    "\n",
    "final_data_subset = final_data[final_data['tagged_rel'] != '']\n",
    "print('we lose {} observations by filtering through our classification of relationship, which is equivalent to {} %'.format(final_data.shape[0] - final_data_subset.shape[0], ((final_data.shape[0] - final_data_subset.shape[0])/final_data.shape[0])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/crismacg/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/crismacg/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/crismacg/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/crismacg/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# ******************************************************************************\n",
    "# Replace part of strings in the representation.\n",
    "# ******************************************************************************\n",
    "\n",
    "# 1. Replace aggresors *********************************************************\n",
    "# -------- Get actors from Actors column \n",
    "\n",
    "final_data['clean_actor'] = final_data['ACTOR1'].str.split('(').str[0]\n",
    "final_data['clean_actor'] = final_data['clean_actor'].str.replace('civilians', '')\n",
    "final_data['temp_clean_actor1'] = final_data['clean_actor'].str.split(':').str[0].str.strip().apply(lambda x: ' ' + str(x) + ' ')\n",
    "final_data['temp_clean_actor2'] = final_data['clean_actor'].str.split(':').str[1].str.strip().apply(lambda x: ' ' + str(x) + ' ')\n",
    "uniq_actors = list(final_data['temp_clean_actor1'].str.lower().dropna().unique()) + list(final_data['temp_clean_actor2'].str.lower().dropna().unique())\n",
    "\n",
    "# Getting those that are unidentified actors & different ways of spelling them\n",
    "list_unident_actors = final_data['NOTES'].str.split('unidentified armed').str[1].str.split(' ').str[1].str.replace('.', '').str.replace(',', '').str.replace(';', '').str.replace(\"'s\", \"\").str.lower().dropna().unique()\n",
    "unident_actors_l = list_unident_actors[((list_unident_actors != 'and') & (list_unident_actors != 'in') & (list_unident_actors != 'on')& (list_unident_actors != 'nan'))]\n",
    "unident_actors = list(map(lambda x: 'unidentified armed '+ str(x), unident_actors_l))\n",
    "unident_actors_v2 = list(map(lambda x: 'armed '+ str(x), unident_actors_l))\n",
    "unident_actors_v3 = list(map(lambda x: 'unidentified '+ str(x), unident_actors_l))\n",
    "unident_actors_v4 = list(map(lambda x: 'unknown armed '+ str(x), unident_actors_l))\n",
    "unident_actors_v5 = list(map(lambda x: 'unknown '+ str(x), unident_actors_l))\n",
    "\n",
    "\n",
    "list_aggrs = uniq_actors + unident_actors + unident_actors_v2 + unident_actors_v3 + unident_actors_v4 + unident_actors_v5+ ['fighter','fighters','anti-houti forces']\n",
    "num = len(list_aggrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/crismacg/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/crismacg/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1281\n",
      "1/1281\n",
      "2/1281\n",
      "3/1281\n",
      "4/1281\n",
      "5/1281\n",
      "6/1281\n",
      "7/1281\n",
      "8/1281\n",
      "9/1281\n",
      "10/1281\n",
      "11/1281\n",
      "12/1281\n",
      "13/1281\n",
      "14/1281\n",
      "15/1281\n",
      "16/1281\n",
      "17/1281\n",
      "18/1281\n",
      "19/1281\n",
      "20/1281\n",
      "21/1281\n",
      "22/1281\n",
      "23/1281\n",
      "24/1281\n",
      "25/1281\n",
      "26/1281\n",
      "27/1281\n",
      "28/1281\n",
      "29/1281\n",
      "30/1281\n",
      "31/1281\n",
      "32/1281\n",
      "33/1281\n",
      "34/1281\n",
      "35/1281\n",
      "36/1281\n",
      "37/1281\n",
      "38/1281\n",
      "39/1281\n",
      "40/1281\n",
      "41/1281\n",
      "42/1281\n",
      "43/1281\n",
      "44/1281\n",
      "45/1281\n",
      "46/1281\n",
      "47/1281\n",
      "48/1281\n",
      "49/1281\n",
      "50/1281\n",
      "51/1281\n",
      "52/1281\n",
      "53/1281\n",
      "54/1281\n",
      "55/1281\n",
      "56/1281\n",
      "57/1281\n",
      "58/1281\n",
      "59/1281\n",
      "60/1281\n",
      "61/1281\n",
      "62/1281\n",
      "63/1281\n",
      "64/1281\n",
      "65/1281\n",
      "66/1281\n",
      "67/1281\n",
      "68/1281\n",
      "69/1281\n",
      "70/1281\n",
      "71/1281\n",
      "72/1281\n",
      "73/1281\n",
      "74/1281\n",
      "75/1281\n",
      "76/1281\n",
      "77/1281\n",
      "78/1281\n",
      "79/1281\n",
      "80/1281\n",
      "81/1281\n",
      "82/1281\n",
      "83/1281\n",
      "84/1281\n",
      "85/1281\n",
      "86/1281\n",
      "87/1281\n",
      "88/1281\n",
      "89/1281\n",
      "90/1281\n",
      "91/1281\n",
      "92/1281\n",
      "93/1281\n",
      "94/1281\n",
      "95/1281\n",
      "96/1281\n",
      "97/1281\n",
      "98/1281\n",
      "99/1281\n",
      "100/1281\n",
      "101/1281\n",
      "102/1281\n",
      "103/1281\n",
      "104/1281\n",
      "105/1281\n",
      "106/1281\n",
      "107/1281\n",
      "108/1281\n",
      "109/1281\n",
      "110/1281\n",
      "111/1281\n",
      "112/1281\n",
      "113/1281\n",
      "114/1281\n",
      "115/1281\n",
      "116/1281\n",
      "117/1281\n",
      "118/1281\n",
      "119/1281\n",
      "120/1281\n",
      "121/1281\n",
      "122/1281\n",
      "123/1281\n",
      "124/1281\n",
      "125/1281\n",
      "126/1281\n",
      "127/1281\n",
      "128/1281\n",
      "129/1281\n",
      "130/1281\n",
      "131/1281\n",
      "132/1281\n",
      "133/1281\n",
      "134/1281\n",
      "135/1281\n",
      "136/1281\n",
      "137/1281\n",
      "138/1281\n",
      "139/1281\n",
      "140/1281\n",
      "141/1281\n",
      "142/1281\n",
      "143/1281\n",
      "144/1281\n",
      "145/1281\n",
      "146/1281\n",
      "147/1281\n",
      "148/1281\n",
      "149/1281\n",
      "150/1281\n",
      "151/1281\n",
      "152/1281\n",
      "153/1281\n",
      "154/1281\n",
      "155/1281\n",
      "156/1281\n",
      "157/1281\n",
      "158/1281\n",
      "159/1281\n",
      "160/1281\n",
      "161/1281\n",
      "162/1281\n",
      "163/1281\n",
      "164/1281\n",
      "165/1281\n",
      "166/1281\n",
      "167/1281\n",
      "168/1281\n",
      "169/1281\n",
      "170/1281\n",
      "171/1281\n",
      "172/1281\n",
      "173/1281\n",
      "174/1281\n",
      "175/1281\n",
      "176/1281\n",
      "177/1281\n",
      "178/1281\n",
      "179/1281\n",
      "180/1281\n",
      "181/1281\n",
      "182/1281\n",
      "183/1281\n",
      "184/1281\n",
      "185/1281\n",
      "186/1281\n",
      "187/1281\n",
      "188/1281\n",
      "189/1281\n",
      "190/1281\n",
      "191/1281\n",
      "192/1281\n",
      "193/1281\n",
      "194/1281\n",
      "195/1281\n",
      "196/1281\n",
      "197/1281\n",
      "198/1281\n",
      "199/1281\n",
      "200/1281\n",
      "201/1281\n",
      "202/1281\n",
      "203/1281\n",
      "204/1281\n",
      "205/1281\n",
      "206/1281\n",
      "207/1281\n",
      "208/1281\n",
      "209/1281\n",
      "210/1281\n",
      "211/1281\n",
      "212/1281\n",
      "213/1281\n",
      "214/1281\n",
      "215/1281\n",
      "216/1281\n",
      "217/1281\n",
      "218/1281\n",
      "219/1281\n",
      "220/1281\n",
      "221/1281\n",
      "222/1281\n",
      "223/1281\n",
      "224/1281\n",
      "225/1281\n",
      "226/1281\n",
      "227/1281\n",
      "228/1281\n",
      "229/1281\n",
      "230/1281\n",
      "231/1281\n",
      "232/1281\n",
      "233/1281\n",
      "234/1281\n",
      "235/1281\n",
      "236/1281\n",
      "237/1281\n",
      "238/1281\n",
      "239/1281\n",
      "240/1281\n",
      "241/1281\n",
      "242/1281\n",
      "243/1281\n",
      "244/1281\n",
      "245/1281\n",
      "246/1281\n",
      "247/1281\n",
      "248/1281\n",
      "249/1281\n",
      "250/1281\n",
      "251/1281\n",
      "252/1281\n",
      "253/1281\n",
      "254/1281\n",
      "255/1281\n",
      "256/1281\n",
      "257/1281\n",
      "258/1281\n",
      "259/1281\n",
      "260/1281\n",
      "261/1281\n",
      "262/1281\n",
      "263/1281\n",
      "264/1281\n",
      "265/1281\n",
      "266/1281\n",
      "267/1281\n",
      "268/1281\n",
      "269/1281\n",
      "270/1281\n",
      "271/1281\n",
      "272/1281\n",
      "273/1281\n",
      "274/1281\n",
      "275/1281\n",
      "276/1281\n",
      "277/1281\n",
      "278/1281\n",
      "279/1281\n",
      "280/1281\n",
      "281/1281\n",
      "282/1281\n",
      "283/1281\n",
      "284/1281\n",
      "285/1281\n",
      "286/1281\n",
      "287/1281\n",
      "288/1281\n",
      "289/1281\n",
      "290/1281\n",
      "291/1281\n",
      "292/1281\n",
      "293/1281\n",
      "294/1281\n",
      "295/1281\n",
      "296/1281\n",
      "297/1281\n",
      "298/1281\n",
      "299/1281\n",
      "300/1281\n",
      "301/1281\n",
      "302/1281\n",
      "303/1281\n",
      "304/1281\n",
      "305/1281\n",
      "306/1281\n",
      "307/1281\n",
      "308/1281\n",
      "309/1281\n",
      "310/1281\n",
      "311/1281\n",
      "312/1281\n",
      "313/1281\n",
      "314/1281\n",
      "315/1281\n",
      "316/1281\n",
      "317/1281\n",
      "318/1281\n",
      "319/1281\n",
      "320/1281\n",
      "321/1281\n",
      "322/1281\n",
      "323/1281\n",
      "324/1281\n",
      "325/1281\n",
      "326/1281\n",
      "327/1281\n",
      "328/1281\n",
      "329/1281\n",
      "330/1281\n",
      "331/1281\n",
      "332/1281\n",
      "333/1281\n",
      "334/1281\n",
      "335/1281\n",
      "336/1281\n",
      "337/1281\n",
      "338/1281\n",
      "339/1281\n",
      "340/1281\n",
      "341/1281\n",
      "342/1281\n",
      "343/1281\n",
      "344/1281\n",
      "345/1281\n",
      "346/1281\n",
      "347/1281\n",
      "348/1281\n",
      "349/1281\n",
      "350/1281\n",
      "351/1281\n",
      "352/1281\n",
      "353/1281\n",
      "354/1281\n",
      "355/1281\n",
      "356/1281\n",
      "357/1281\n",
      "358/1281\n",
      "359/1281\n",
      "360/1281\n",
      "361/1281\n",
      "362/1281\n",
      "363/1281\n",
      "364/1281\n",
      "365/1281\n",
      "366/1281\n",
      "367/1281\n",
      "368/1281\n",
      "369/1281\n",
      "370/1281\n",
      "371/1281\n",
      "372/1281\n",
      "373/1281\n",
      "374/1281\n",
      "375/1281\n",
      "376/1281\n",
      "377/1281\n",
      "378/1281\n",
      "379/1281\n",
      "380/1281\n",
      "381/1281\n",
      "382/1281\n",
      "383/1281\n",
      "384/1281\n",
      "385/1281\n",
      "386/1281\n",
      "387/1281\n",
      "388/1281\n",
      "389/1281\n",
      "390/1281\n",
      "391/1281\n",
      "392/1281\n",
      "393/1281\n",
      "394/1281\n",
      "395/1281\n",
      "396/1281\n",
      "397/1281\n",
      "398/1281\n",
      "399/1281\n",
      "400/1281\n",
      "401/1281\n",
      "402/1281\n",
      "403/1281\n",
      "404/1281\n",
      "405/1281\n",
      "406/1281\n",
      "407/1281\n",
      "408/1281\n",
      "409/1281\n",
      "410/1281\n",
      "411/1281\n",
      "412/1281\n",
      "413/1281\n",
      "414/1281\n",
      "415/1281\n",
      "416/1281\n",
      "417/1281\n",
      "418/1281\n",
      "419/1281\n",
      "420/1281\n",
      "421/1281\n",
      "422/1281\n",
      "423/1281\n",
      "424/1281\n",
      "425/1281\n",
      "426/1281\n",
      "427/1281\n",
      "428/1281\n",
      "429/1281\n",
      "430/1281\n",
      "431/1281\n",
      "432/1281\n",
      "433/1281\n",
      "434/1281\n",
      "435/1281\n",
      "436/1281\n",
      "437/1281\n",
      "438/1281\n",
      "439/1281\n",
      "440/1281\n",
      "441/1281\n",
      "442/1281\n",
      "443/1281\n",
      "444/1281\n",
      "445/1281\n",
      "446/1281\n",
      "447/1281\n",
      "448/1281\n",
      "449/1281\n",
      "450/1281\n",
      "451/1281\n",
      "452/1281\n",
      "453/1281\n",
      "454/1281\n",
      "455/1281\n",
      "456/1281\n",
      "457/1281\n",
      "458/1281\n",
      "459/1281\n",
      "460/1281\n",
      "461/1281\n",
      "462/1281\n",
      "463/1281\n",
      "464/1281\n",
      "465/1281\n",
      "466/1281\n",
      "467/1281\n",
      "468/1281\n",
      "469/1281\n",
      "470/1281\n",
      "471/1281\n",
      "472/1281\n",
      "473/1281\n",
      "474/1281\n",
      "475/1281\n",
      "476/1281\n",
      "477/1281\n",
      "478/1281\n",
      "479/1281\n",
      "480/1281\n",
      "481/1281\n",
      "482/1281\n",
      "483/1281\n",
      "484/1281\n",
      "485/1281\n",
      "486/1281\n",
      "487/1281\n",
      "488/1281\n",
      "489/1281\n",
      "490/1281\n",
      "491/1281\n",
      "492/1281\n",
      "493/1281\n",
      "494/1281\n",
      "495/1281\n",
      "496/1281\n",
      "497/1281\n",
      "498/1281\n",
      "499/1281\n",
      "500/1281\n",
      "501/1281\n",
      "502/1281\n",
      "503/1281\n",
      "504/1281\n",
      "505/1281\n",
      "506/1281\n",
      "507/1281\n",
      "508/1281\n",
      "509/1281\n",
      "510/1281\n",
      "511/1281\n",
      "512/1281\n",
      "513/1281\n",
      "514/1281\n",
      "515/1281\n",
      "516/1281\n",
      "517/1281\n",
      "518/1281\n",
      "519/1281\n",
      "520/1281\n",
      "521/1281\n",
      "522/1281\n",
      "523/1281\n",
      "524/1281\n",
      "525/1281\n",
      "526/1281\n",
      "527/1281\n",
      "528/1281\n",
      "529/1281\n",
      "530/1281\n",
      "531/1281\n",
      "532/1281\n",
      "533/1281\n",
      "534/1281\n",
      "535/1281\n",
      "536/1281\n",
      "537/1281\n",
      "538/1281\n",
      "539/1281\n",
      "540/1281\n",
      "541/1281\n",
      "542/1281\n",
      "543/1281\n",
      "544/1281\n",
      "545/1281\n",
      "546/1281\n",
      "547/1281\n",
      "548/1281\n",
      "549/1281\n",
      "550/1281\n",
      "551/1281\n",
      "552/1281\n",
      "553/1281\n",
      "554/1281\n",
      "555/1281\n",
      "556/1281\n",
      "557/1281\n",
      "558/1281\n",
      "559/1281\n",
      "560/1281\n",
      "561/1281\n",
      "562/1281\n",
      "563/1281\n",
      "564/1281\n",
      "565/1281\n",
      "566/1281\n",
      "567/1281\n",
      "568/1281\n",
      "569/1281\n",
      "570/1281\n",
      "571/1281\n",
      "572/1281\n",
      "573/1281\n",
      "574/1281\n",
      "575/1281\n",
      "576/1281\n",
      "577/1281\n",
      "578/1281\n",
      "579/1281\n",
      "580/1281\n",
      "581/1281\n",
      "582/1281\n",
      "583/1281\n",
      "584/1281\n",
      "585/1281\n",
      "586/1281\n",
      "587/1281\n",
      "588/1281\n",
      "589/1281\n",
      "590/1281\n",
      "591/1281\n",
      "592/1281\n",
      "593/1281\n",
      "594/1281\n",
      "595/1281\n",
      "596/1281\n",
      "597/1281\n",
      "598/1281\n",
      "599/1281\n",
      "600/1281\n",
      "601/1281\n",
      "602/1281\n",
      "603/1281\n",
      "604/1281\n",
      "605/1281\n",
      "606/1281\n",
      "607/1281\n",
      "608/1281\n",
      "609/1281\n",
      "610/1281\n",
      "611/1281\n",
      "612/1281\n",
      "613/1281\n",
      "614/1281\n",
      "615/1281\n",
      "616/1281\n",
      "617/1281\n",
      "618/1281\n",
      "619/1281\n",
      "620/1281\n",
      "621/1281\n",
      "622/1281\n",
      "623/1281\n",
      "624/1281\n",
      "625/1281\n",
      "626/1281\n",
      "627/1281\n",
      "628/1281\n",
      "629/1281\n",
      "630/1281\n",
      "631/1281\n",
      "632/1281\n",
      "633/1281\n",
      "634/1281\n",
      "635/1281\n",
      "636/1281\n",
      "637/1281\n",
      "638/1281\n",
      "639/1281\n",
      "640/1281\n",
      "641/1281\n",
      "642/1281\n",
      "643/1281\n",
      "644/1281\n",
      "645/1281\n",
      "646/1281\n",
      "647/1281\n",
      "648/1281\n",
      "649/1281\n",
      "650/1281\n",
      "651/1281\n",
      "652/1281\n",
      "653/1281\n",
      "654/1281\n",
      "655/1281\n",
      "656/1281\n",
      "657/1281\n",
      "658/1281\n",
      "659/1281\n",
      "660/1281\n",
      "661/1281\n",
      "662/1281\n",
      "663/1281\n",
      "664/1281\n",
      "665/1281\n",
      "666/1281\n",
      "667/1281\n",
      "668/1281\n",
      "669/1281\n",
      "670/1281\n",
      "671/1281\n",
      "672/1281\n",
      "673/1281\n",
      "674/1281\n",
      "675/1281\n",
      "676/1281\n",
      "677/1281\n",
      "678/1281\n",
      "679/1281\n",
      "680/1281\n",
      "681/1281\n",
      "682/1281\n",
      "683/1281\n",
      "684/1281\n",
      "685/1281\n",
      "686/1281\n",
      "687/1281\n",
      "688/1281\n",
      "689/1281\n",
      "690/1281\n",
      "691/1281\n",
      "692/1281\n",
      "693/1281\n",
      "694/1281\n",
      "695/1281\n",
      "696/1281\n",
      "697/1281\n",
      "698/1281\n",
      "699/1281\n",
      "700/1281\n",
      "701/1281\n",
      "702/1281\n",
      "703/1281\n",
      "704/1281\n",
      "705/1281\n",
      "706/1281\n",
      "707/1281\n",
      "708/1281\n",
      "709/1281\n",
      "710/1281\n",
      "711/1281\n",
      "712/1281\n",
      "713/1281\n",
      "714/1281\n",
      "715/1281\n",
      "716/1281\n",
      "717/1281\n",
      "718/1281\n",
      "719/1281\n",
      "720/1281\n",
      "721/1281\n",
      "722/1281\n",
      "723/1281\n",
      "724/1281\n",
      "725/1281\n",
      "726/1281\n",
      "727/1281\n",
      "728/1281\n",
      "729/1281\n",
      "730/1281\n",
      "731/1281\n",
      "732/1281\n",
      "733/1281\n",
      "734/1281\n",
      "735/1281\n",
      "736/1281\n",
      "737/1281\n",
      "738/1281\n",
      "739/1281\n",
      "740/1281\n",
      "741/1281\n",
      "742/1281\n",
      "743/1281\n",
      "744/1281\n",
      "745/1281\n",
      "746/1281\n",
      "747/1281\n",
      "748/1281\n",
      "749/1281\n",
      "750/1281\n",
      "751/1281\n",
      "752/1281\n",
      "753/1281\n",
      "754/1281\n",
      "755/1281\n",
      "756/1281\n",
      "757/1281\n",
      "758/1281\n",
      "759/1281\n",
      "760/1281\n",
      "761/1281\n",
      "762/1281\n",
      "763/1281\n",
      "764/1281\n",
      "765/1281\n",
      "766/1281\n",
      "767/1281\n",
      "768/1281\n",
      "769/1281\n",
      "770/1281\n",
      "771/1281\n",
      "772/1281\n",
      "773/1281\n",
      "774/1281\n",
      "775/1281\n",
      "776/1281\n",
      "777/1281\n",
      "778/1281\n",
      "779/1281\n",
      "780/1281\n",
      "781/1281\n",
      "782/1281\n",
      "783/1281\n",
      "784/1281\n",
      "785/1281\n",
      "786/1281\n",
      "787/1281\n",
      "788/1281\n",
      "789/1281\n",
      "790/1281\n",
      "791/1281\n",
      "792/1281\n",
      "793/1281\n",
      "794/1281\n",
      "795/1281\n",
      "796/1281\n",
      "797/1281\n",
      "798/1281\n",
      "799/1281\n",
      "800/1281\n",
      "801/1281\n",
      "802/1281\n",
      "803/1281\n",
      "804/1281\n",
      "805/1281\n",
      "806/1281\n",
      "807/1281\n",
      "808/1281\n",
      "809/1281\n",
      "810/1281\n",
      "811/1281\n",
      "812/1281\n",
      "813/1281\n",
      "814/1281\n",
      "815/1281\n",
      "816/1281\n",
      "817/1281\n",
      "818/1281\n",
      "819/1281\n",
      "820/1281\n",
      "821/1281\n",
      "822/1281\n",
      "823/1281\n",
      "824/1281\n",
      "825/1281\n",
      "826/1281\n",
      "827/1281\n",
      "828/1281\n",
      "829/1281\n",
      "830/1281\n",
      "831/1281\n",
      "832/1281\n",
      "833/1281\n",
      "834/1281\n",
      "835/1281\n",
      "836/1281\n",
      "837/1281\n",
      "838/1281\n",
      "839/1281\n",
      "840/1281\n",
      "841/1281\n",
      "842/1281\n",
      "843/1281\n",
      "844/1281\n",
      "845/1281\n",
      "846/1281\n",
      "847/1281\n",
      "848/1281\n",
      "849/1281\n",
      "850/1281\n",
      "851/1281\n",
      "852/1281\n",
      "853/1281\n",
      "854/1281\n",
      "855/1281\n",
      "856/1281\n",
      "857/1281\n",
      "858/1281\n",
      "859/1281\n",
      "860/1281\n",
      "861/1281\n",
      "862/1281\n",
      "863/1281\n",
      "864/1281\n",
      "865/1281\n",
      "866/1281\n",
      "867/1281\n",
      "868/1281\n",
      "869/1281\n",
      "870/1281\n",
      "871/1281\n",
      "872/1281\n",
      "873/1281\n",
      "874/1281\n",
      "875/1281\n",
      "876/1281\n",
      "877/1281\n",
      "878/1281\n",
      "879/1281\n",
      "880/1281\n",
      "881/1281\n",
      "882/1281\n",
      "883/1281\n",
      "884/1281\n",
      "885/1281\n",
      "886/1281\n",
      "887/1281\n",
      "888/1281\n",
      "889/1281\n",
      "890/1281\n",
      "891/1281\n",
      "892/1281\n",
      "893/1281\n",
      "894/1281\n",
      "895/1281\n",
      "896/1281\n",
      "897/1281\n",
      "898/1281\n",
      "899/1281\n",
      "900/1281\n",
      "901/1281\n",
      "902/1281\n",
      "903/1281\n",
      "904/1281\n",
      "905/1281\n",
      "906/1281\n",
      "907/1281\n",
      "908/1281\n",
      "909/1281\n",
      "910/1281\n",
      "911/1281\n",
      "912/1281\n",
      "913/1281\n",
      "914/1281\n",
      "915/1281\n",
      "916/1281\n",
      "917/1281\n",
      "918/1281\n",
      "919/1281\n",
      "920/1281\n",
      "921/1281\n",
      "922/1281\n",
      "923/1281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "924/1281\n",
      "925/1281\n",
      "926/1281\n",
      "927/1281\n",
      "928/1281\n",
      "929/1281\n",
      "930/1281\n",
      "931/1281\n",
      "932/1281\n",
      "933/1281\n",
      "934/1281\n",
      "935/1281\n",
      "936/1281\n",
      "937/1281\n",
      "938/1281\n",
      "939/1281\n",
      "940/1281\n",
      "941/1281\n",
      "942/1281\n",
      "943/1281\n",
      "944/1281\n",
      "945/1281\n",
      "946/1281\n",
      "947/1281\n",
      "948/1281\n",
      "949/1281\n",
      "950/1281\n",
      "951/1281\n",
      "952/1281\n",
      "953/1281\n",
      "954/1281\n",
      "955/1281\n",
      "956/1281\n",
      "957/1281\n",
      "958/1281\n",
      "959/1281\n",
      "960/1281\n",
      "961/1281\n",
      "962/1281\n",
      "963/1281\n",
      "964/1281\n",
      "965/1281\n",
      "966/1281\n",
      "967/1281\n",
      "968/1281\n",
      "969/1281\n",
      "970/1281\n",
      "971/1281\n",
      "972/1281\n",
      "973/1281\n",
      "974/1281\n",
      "975/1281\n",
      "976/1281\n",
      "977/1281\n",
      "978/1281\n",
      "979/1281\n",
      "980/1281\n",
      "981/1281\n",
      "982/1281\n",
      "983/1281\n",
      "984/1281\n",
      "985/1281\n",
      "986/1281\n",
      "987/1281\n",
      "988/1281\n",
      "989/1281\n",
      "990/1281\n",
      "991/1281\n",
      "992/1281\n",
      "993/1281\n",
      "994/1281\n",
      "995/1281\n",
      "996/1281\n",
      "997/1281\n",
      "998/1281\n",
      "999/1281\n",
      "1000/1281\n",
      "1001/1281\n",
      "1002/1281\n",
      "1003/1281\n",
      "1004/1281\n",
      "1005/1281\n",
      "1006/1281\n",
      "1007/1281\n",
      "1008/1281\n",
      "1009/1281\n",
      "1010/1281\n",
      "1011/1281\n",
      "1012/1281\n",
      "1013/1281\n",
      "1014/1281\n",
      "1015/1281\n",
      "1016/1281\n",
      "1017/1281\n",
      "1018/1281\n",
      "1019/1281\n",
      "1020/1281\n",
      "1021/1281\n",
      "1022/1281\n",
      "1023/1281\n",
      "1024/1281\n",
      "1025/1281\n",
      "1026/1281\n",
      "1027/1281\n",
      "1028/1281\n",
      "1029/1281\n",
      "1030/1281\n",
      "1031/1281\n",
      "1032/1281\n",
      "1033/1281\n",
      "1034/1281\n",
      "1035/1281\n",
      "1036/1281\n",
      "1037/1281\n",
      "1038/1281\n",
      "1039/1281\n",
      "1040/1281\n",
      "1041/1281\n",
      "1042/1281\n",
      "1043/1281\n",
      "1044/1281\n",
      "1045/1281\n",
      "1046/1281\n",
      "1047/1281\n",
      "1048/1281\n",
      "1049/1281\n",
      "1050/1281\n",
      "1051/1281\n",
      "1052/1281\n",
      "1053/1281\n",
      "1054/1281\n",
      "1055/1281\n",
      "1056/1281\n",
      "1057/1281\n",
      "1058/1281\n",
      "1059/1281\n",
      "1060/1281\n",
      "1061/1281\n",
      "1062/1281\n",
      "1063/1281\n",
      "1064/1281\n",
      "1065/1281\n",
      "1066/1281\n",
      "1067/1281\n",
      "1068/1281\n",
      "1069/1281\n",
      "1070/1281\n",
      "1071/1281\n",
      "1072/1281\n",
      "1073/1281\n",
      "1074/1281\n",
      "1075/1281\n",
      "1076/1281\n",
      "1077/1281\n",
      "1078/1281\n",
      "1079/1281\n",
      "1080/1281\n",
      "1081/1281\n",
      "1082/1281\n",
      "1083/1281\n",
      "1084/1281\n",
      "1085/1281\n",
      "1086/1281\n",
      "1087/1281\n",
      "1088/1281\n",
      "1089/1281\n",
      "1090/1281\n",
      "1091/1281\n",
      "1092/1281\n",
      "1093/1281\n",
      "1094/1281\n",
      "1095/1281\n",
      "1096/1281\n",
      "1097/1281\n",
      "1098/1281\n",
      "1099/1281\n",
      "1100/1281\n",
      "1101/1281\n",
      "1102/1281\n",
      "1103/1281\n",
      "1104/1281\n",
      "1105/1281\n",
      "1106/1281\n",
      "1107/1281\n",
      "1108/1281\n",
      "1109/1281\n",
      "1110/1281\n",
      "1111/1281\n",
      "1112/1281\n",
      "1113/1281\n",
      "1114/1281\n",
      "1115/1281\n",
      "1116/1281\n",
      "1117/1281\n",
      "1118/1281\n",
      "1119/1281\n",
      "1120/1281\n",
      "1121/1281\n",
      "1122/1281\n",
      "1123/1281\n",
      "1124/1281\n",
      "1125/1281\n",
      "1126/1281\n",
      "1127/1281\n",
      "1128/1281\n",
      "1129/1281\n",
      "1130/1281\n",
      "1131/1281\n",
      "1132/1281\n",
      "1133/1281\n",
      "1134/1281\n",
      "1135/1281\n",
      "1136/1281\n",
      "1137/1281\n",
      "1138/1281\n",
      "1139/1281\n",
      "1140/1281\n",
      "1141/1281\n",
      "1142/1281\n",
      "1143/1281\n",
      "1144/1281\n",
      "1145/1281\n",
      "1146/1281\n",
      "1147/1281\n",
      "1148/1281\n",
      "1149/1281\n",
      "1150/1281\n",
      "1151/1281\n",
      "1152/1281\n",
      "1153/1281\n",
      "1154/1281\n",
      "1155/1281\n",
      "1156/1281\n",
      "1157/1281\n",
      "1158/1281\n",
      "1159/1281\n",
      "1160/1281\n",
      "1161/1281\n",
      "1162/1281\n",
      "1163/1281\n",
      "1164/1281\n",
      "1165/1281\n",
      "1166/1281\n",
      "1167/1281\n",
      "1168/1281\n",
      "1169/1281\n",
      "1170/1281\n",
      "1171/1281\n",
      "1172/1281\n",
      "1173/1281\n",
      "1174/1281\n",
      "1175/1281\n",
      "1176/1281\n",
      "1177/1281\n",
      "1178/1281\n",
      "1179/1281\n",
      "1180/1281\n",
      "1181/1281\n",
      "1182/1281\n",
      "1183/1281\n",
      "1184/1281\n",
      "1185/1281\n",
      "1186/1281\n",
      "1187/1281\n",
      "1188/1281\n",
      "1189/1281\n",
      "1190/1281\n",
      "1191/1281\n",
      "1192/1281\n",
      "1193/1281\n",
      "1194/1281\n",
      "1195/1281\n",
      "1196/1281\n",
      "1197/1281\n",
      "1198/1281\n",
      "1199/1281\n",
      "1200/1281\n",
      "1201/1281\n",
      "1202/1281\n",
      "1203/1281\n",
      "1204/1281\n",
      "1205/1281\n",
      "1206/1281\n",
      "1207/1281\n",
      "1208/1281\n",
      "1209/1281\n",
      "1210/1281\n",
      "1211/1281\n",
      "1212/1281\n",
      "1213/1281\n",
      "1214/1281\n",
      "1215/1281\n",
      "1216/1281\n",
      "1217/1281\n",
      "1218/1281\n",
      "1219/1281\n",
      "1220/1281\n",
      "1221/1281\n",
      "1222/1281\n",
      "1223/1281\n",
      "1224/1281\n",
      "1225/1281\n",
      "1226/1281\n",
      "1227/1281\n",
      "1228/1281\n",
      "1229/1281\n",
      "1230/1281\n",
      "1231/1281\n",
      "1232/1281\n",
      "1233/1281\n",
      "1234/1281\n",
      "1235/1281\n",
      "1236/1281\n",
      "1237/1281\n",
      "1238/1281\n",
      "1239/1281\n",
      "1240/1281\n",
      "1241/1281\n",
      "1242/1281\n",
      "1243/1281\n",
      "1244/1281\n",
      "1245/1281\n",
      "1246/1281\n",
      "1247/1281\n",
      "1248/1281\n",
      "1249/1281\n",
      "1250/1281\n",
      "1251/1281\n",
      "1252/1281\n",
      "1253/1281\n",
      "1254/1281\n",
      "1255/1281\n",
      "1256/1281\n",
      "1257/1281\n",
      "1258/1281\n",
      "1259/1281\n",
      "1260/1281\n",
      "1261/1281\n",
      "1262/1281\n",
      "1263/1281\n",
      "1264/1281\n",
      "1265/1281\n",
      "1266/1281\n",
      "1267/1281\n",
      "1268/1281\n",
      "1269/1281\n",
      "1270/1281\n",
      "1271/1281\n",
      "1272/1281\n",
      "1273/1281\n",
      "1274/1281\n",
      "1275/1281\n",
      "1276/1281\n",
      "1277/1281\n",
      "1278/1281\n",
      "1279/1281\n",
      "1280/1281\n",
      "end loop\n"
     ]
    }
   ],
   "source": [
    "# --------\n",
    "final_data['tagged_str'] = final_data['NOTES']\n",
    "for cnt, token in enumerate(list_aggrs):\n",
    "    if len(token.strip()) >= 3: \n",
    "        if 'civilians'not in token: \n",
    "            final_data['tagged_str'] = final_data['tagged_str'].str.lower().str.replace(token, 'aggresor')\n",
    "    print(str(cnt) + '/' + str(num))\n",
    "print('end loop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/crismacg/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/crismacg/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "final_data['tagged_str'] = final_data['tagged_str'].str.lower().str.replace('aggresors', 'AGGRESOR')\n",
    "final_data['tagged_str'] = final_data['tagged_str'].str.lower().str.replace('aggresor', 'AGGRESOR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21597, 35)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = final_data[final_data['tagged_str'].str.contains('AGGRESOR')]\n",
    "x.shape # These are for how many we did NOT get the tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we lose 19185 observations by replacing aggresor in phrase, which is equivalent to 47.04281300573783 %\n"
     ]
    }
   ],
   "source": [
    "final_data_subset = final_data[final_data['tagged_str'].str.contains('AGGRESOR')]\n",
    "print('we lose {} observations by replacing aggresor in phrase, which is equivalent to {} %'.format(final_data.shape[0] - final_data_subset.shape[0], ((final_data.shape[0] - final_data_subset.shape[0])/final_data.shape[0])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/14\n",
      "1/14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/crismacg/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/14\n",
      "3/14\n",
      "4/14\n",
      "5/14\n",
      "6/14\n",
      "7/14\n",
      "8/14\n",
      "9/14\n",
      "10/14\n",
      "11/14\n",
      "12/14\n",
      "13/14\n",
      "end loop\n"
     ]
    }
   ],
   "source": [
    "# 2. Replace civilians *********************************************************\n",
    "list_civs = ['passengers', 'civilians','residents' 'passenger', 'civilian', 'family', 'families', 'people', 'tourist','tourists' 'villagers', 'women', 'children', 'citizen', 'citizens', 'population']\n",
    "\n",
    "for cnt, token in enumerate(list_civs):\n",
    "    if token:\n",
    "        final_data['tagged_str'] = final_data['tagged_str'].str.lower().str.replace(token,'victim')\n",
    "        print(str(cnt) + '/' + str(len(list_civs)))\n",
    "print('end loop')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/crismacg/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/crismacg/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/crismacg/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "final_data['tagged_str'] = final_data['tagged_str'].str.lower().str.replace('victims', 'VICTIM')\n",
    "final_data['tagged_str'] = final_data['tagged_str'].str.lower().str.replace('victim', 'VICTIM')\n",
    "final_data['tagged_str'] = final_data['tagged_str'].str.replace('aggresor', 'AGGRESOR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25375, 35)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = final_data[~final_data['tagged_str'].str.contains('VICTIM')]\n",
    "y.shape # These are for how many we did NOT get the tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we lose 25375 observations by replacing victim in phrase, which is equivalent to 62.22107792653622 %\n"
     ]
    }
   ],
   "source": [
    "final_data_subset = final_data[final_data['tagged_str'].str.contains('VICTIM')]\n",
    "print('we lose {} observations by replacing victim in phrase, which is equivalent to {} %'.format(final_data.shape[0] - final_data_subset.shape[0], ((final_data.shape[0] - final_data_subset.shape[0])/final_data.shape[0])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Subset our data for this case *********************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33706 dont have victim & aggressor, which is equivalent to 82.64920798391448 %\n"
     ]
    }
   ],
   "source": [
    "#Tags that have both aggresor and victim labels \n",
    "final_data_subset = final_data[((final_data['tagged_str'].str.contains('AGGRESOR')) & (final_data['tagged_str'].str.contains('VICTIM')))]\n",
    "print('{} dont have victim & aggressor, which is equivalent to {} %'.format(final_data.shape[0] - final_data_subset.shape[0], ((final_data.shape[0] - final_data_subset.shape[0])/final_data.shape[0])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10854 dont have victim OR aggressor, which is equivalent to 26.61468294835957 %\n"
     ]
    }
   ],
   "source": [
    "final_data_subset = final_data[((final_data['tagged_str'].str.contains('AGGRESOR')) | (final_data['tagged_str'].str.contains('VICTIM')))]\n",
    "print('{} dont have victim OR aggressor, which is equivalent to {} %'.format(final_data.shape[0] - final_data_subset.shape[0], ((final_data.shape[0] - final_data_subset.shape[0])/final_data.shape[0])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12325 dont have victim OR aggressor, NOR relationship, which is equivalent to 30.221666421460448 %\n",
      "Final Dataset for training has 28457 observations\n"
     ]
    }
   ],
   "source": [
    "final_data_subset = final_data[(final_data['tagged_rel'] != '' ) & ((final_data['tagged_str'].str.contains('AGGRESOR')) | (final_data['tagged_str'].str.contains('VICTIM')))]\n",
    "print('{} dont have victim OR aggressor, NOR relationship, which is equivalent to {} %'.format(final_data.shape[0] - final_data_subset.shape[0], ((final_data.shape[0] - final_data_subset.shape[0])/final_data.shape[0])*100))\n",
    "final = final_data_subset\n",
    "print('Final Dataset for training has {} observations'.format(final.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('Data/data_prepr.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_v2 = final_data[(final_data['tagged_rel'] != '' ) & ((final_data['tagged_str'].str.contains('AGGRESOR')) & (final_data['tagged_str'].str.contains('VICTIM')))]\n",
    "print('{} dont have victim AND aggressor, NOR relationship, which is equivalent to {} %'.format(final_data.shape[0] - final_v2.shape[0], ((final_data.shape[0] - final_data_v2.shape[0])/final_data.shape[0])*100))\n",
    "\n",
    "final_v2.to_csv('Data/data_prepr_v2.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
